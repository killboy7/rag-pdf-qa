# ðŸ“˜ PDF-Based Retrieval-Augmented Generation (RAG)

A fully **local Retrieval-Augmented Generation (RAG)** system that enables natural-language querying of PDFs using **Ollama**, **FAISS**, and **LangChain**.

This project demonstrates how to:

- ðŸ“„ Ingest and chunk structured PDFs  
- ðŸ§  Generate embeddings locally using Ollama  
- ðŸ” Store and retrieve vectors with FAISS  
- ðŸ¤– Produce grounded answers using a local LLM  

---

## ðŸš€ Features

- ðŸ“„ PDF ingestion via **PyMuPDF**
- ðŸ§  Semantic search using **FAISS**
- ðŸ”— Retrieval-Augmented Generation (RAG) pipeline
- ðŸ¤– Local embeddings and LLMs via **Ollama**
- ðŸ›‘ Reduced hallucinations through prompt grounding
- ðŸ’» Fully **offline** after initial setup

---

## ðŸ—ï¸ Project Architecture

User Question  
â†“  
Embedding (nomic-embed-text)  
â†“  
FAISS Vector Search  
â†“  
Relevant PDF Chunks  
â†“  
LLM (llama3.1)  
â†“  
Grounded Answer  

---

## ðŸ“‚ Project Structure

rag-pdf-qa/  
â”œâ”€â”€ ingest.py        # PDF ingestion & FAISS index creation  
â”œâ”€â”€ query.py         # Query-time RAG pipeline  
â”œâ”€â”€ data/            # PDF inputs (git-ignored)  
â””â”€â”€ index/           # FAISS index files (git-ignored)  

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
git clone https://github.com/hasham-tdl/rag-pdf-qa.git  
cd rag-pdf-qa  

### 2ï¸âƒ£ Create and activate a virtual environment
python -m venv venv  
venv\Scripts\activate  

### 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt  

### 4ï¸âƒ£ Install & run Ollama

Download Ollama from:  
https://ollama.com  

Pull the required models:
ollama pull nomic-embed-text  
ollama pull llama3.1  

### 5ï¸âƒ£ Add your PDF
data/book.pdf  

### 6ï¸âƒ£ Build the FAISS index
python ingest.py  

### 7ï¸âƒ£ Query the document
python query.py  

---

## ðŸ§  Example Query

Ask a question:  
> What is OAuth authentication?  

OAuth is an authorization framework that...  

---

## ðŸ§ª Models Used

Purpose: Embeddings â€” nomic-embed-text  
Purpose: LLM â€” llama3.1  

---

## ðŸ“Œ Notes

- Answers are generated **only from retrieved PDF content**
- If relevant information is not found, the system responds accordingly
- Chunking strategy is optimized for QA-style documents
- Designed for **local, private, and offline** usage
